{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c73ed405087432",
   "metadata": {},
   "source": [
    "# MFCC LFCC 추출기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:48:31.418081Z",
     "start_time": "2024-11-24T13:44:27.938324Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for-2seconds/training/fake: 100%|██████████| 6978/6978 [00:53<00:00, 131.19it/s]\n",
      "Processing for-2seconds/training/real: 100%|██████████| 6978/6978 [00:52<00:00, 132.51it/s]\n",
      "Processing for-2seconds/testing/fake: 100%|██████████| 544/544 [00:04<00:00, 130.33it/s]\n",
      "Processing for-2seconds/testing/real: 100%|██████████| 544/544 [00:04<00:00, 126.74it/s]\n",
      "Processing for-2seconds/validation/fake: 100%|██████████| 1413/1413 [00:10<00:00, 130.41it/s]\n",
      "Processing for-2seconds/validation/real: 100%|██████████| 1413/1413 [00:10<00:00, 130.29it/s]\n",
      "Processing for-rerecorded/training/fake: 100%|██████████| 5104/5104 [00:41<00:00, 124.39it/s]\n",
      "Processing for-rerecorded/training/real: 100%|██████████| 5104/5104 [00:40<00:00, 126.73it/s]\n",
      "Processing for-rerecorded/testing/fake: 100%|██████████| 408/408 [00:03<00:00, 125.08it/s]\n",
      "Processing for-rerecorded/testing/real: 100%|██████████| 408/408 [00:03<00:00, 128.74it/s]\n",
      "Processing for-rerecorded/validation/fake: 100%|██████████| 1143/1143 [00:09<00:00, 125.08it/s]\n",
      "Processing for-rerecorded/validation/real: 100%|██████████| 1101/1101 [00:08<00:00, 126.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed!\n",
      "\n",
      "Checking saved features shapes...\n",
      "melspec: (1, 64, 32)\n",
      "melspec_delta: (1, 64, 32)\n",
      "melspec_delta_delta: (1, 64, 32)\n",
      "lfcc: (1, 64, 32)\n",
      "lfcc_delta: (1, 64, 32)\n",
      "lfcc_delta_delta: (1, 64, 32)\n",
      "melspec: (1, 64, 32)\n",
      "melspec_delta: (1, 64, 32)\n",
      "melspec_delta_delta: (1, 64, 32)\n",
      "lfcc: (1, 64, 32)\n",
      "lfcc_delta: (1, 64, 32)\n",
      "lfcc_delta_delta: (1, 64, 32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 기본 경로 설정\n",
    "base_dir = r\"C:\\Users\\tjdwn\\Downloads\\archive\"\n",
    "save_dir = \"audio_features\"\n",
    "\n",
    "# 저장 디렉토리 생성\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 멜스펙트로그램 변환기 설정\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=32000,  # 기본 샘플레이트\n",
    "    n_mels=64,         # 멜 필터뱅크 수\n",
    "    n_fft=2048,\n",
    "    hop_length=1024\n",
    ")\n",
    "\n",
    "# LFCC 변환기 설정 - n_lfcc를 64로 수정\n",
    "lfcc_transform = torchaudio.transforms.LFCC(\n",
    "    sample_rate=32000,\n",
    "    n_lfcc=64,         # LFCC 계수 수를 64로 변경\n",
    "    n_filter=128,      # 필터 수 증가\n",
    "    speckwargs={\"n_fft\": 2048, \"hop_length\": 1024}\n",
    ")\n",
    "\n",
    "# Delta와 Delta-Delta 계산기 설정\n",
    "compute_deltas = torchaudio.transforms.ComputeDeltas(win_length=9)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mel_transform = mel_transform.to(device)\n",
    "lfcc_transform = lfcc_transform.to(device)\n",
    "compute_deltas = compute_deltas.to(device)\n",
    "\n",
    "def extract_features(audio_path):\n",
    "    # 오디오 로드\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    waveform = waveform.to(device)\n",
    "    \n",
    "    # 멜스펙트로그램 추출\n",
    "    mel_spec = mel_transform(waveform)\n",
    "    mel_spec_db = torchaudio.transforms.AmplitudeToDB()(mel_spec)\n",
    "    \n",
    "    # Delta와 Delta-Delta 특징 추출 (멜스펙트로그램)\n",
    "    mel_deltas = compute_deltas(mel_spec_db)\n",
    "    mel_delta_deltas = compute_deltas(mel_deltas)\n",
    "    \n",
    "    # LFCC 특징 추출\n",
    "    lfcc = lfcc_transform(waveform)\n",
    "    # LFCC에 대한 Delta와 Delta-Delta\n",
    "    lfcc_deltas = compute_deltas(lfcc)\n",
    "    lfcc_delta_deltas = compute_deltas(lfcc_deltas)\n",
    "    \n",
    "    # 모든 특징을 하나의 텐서로 결합\n",
    "    features = {\n",
    "        'melspec': mel_spec_db.cpu().numpy(),\n",
    "        'melspec_delta': mel_deltas.cpu().numpy(),\n",
    "        'melspec_delta_delta': mel_delta_deltas.cpu().numpy(),\n",
    "        'lfcc': lfcc.cpu().numpy(),\n",
    "        'lfcc_delta': lfcc_deltas.cpu().numpy(),\n",
    "        'lfcc_delta_delta': lfcc_delta_deltas.cpu().numpy()\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 데이터 처리\n",
    "for folder_name in ['for-2seconds', 'for-rerecorded']:\n",
    "    dataset_save_dir = os.path.join(save_dir, folder_name)\n",
    "    os.makedirs(dataset_save_dir, exist_ok=True)\n",
    "    \n",
    "    for split in ['training', 'testing', 'validation']:\n",
    "        split_save_dir = os.path.join(dataset_save_dir, split)\n",
    "        os.makedirs(split_save_dir, exist_ok=True)\n",
    "        \n",
    "        for label in ['fake', 'real']:\n",
    "            label_save_dir = os.path.join(split_save_dir, label)\n",
    "            os.makedirs(label_save_dir, exist_ok=True)\n",
    "            \n",
    "            # 각 특징 타입에 대한 디렉토리 생성\n",
    "            feature_types = ['melspec', 'melspec_delta', 'melspec_delta_delta', \n",
    "                           'lfcc', 'lfcc_delta', 'lfcc_delta_delta']\n",
    "            for feature_type in feature_types:\n",
    "                os.makedirs(os.path.join(label_save_dir, feature_type), exist_ok=True)\n",
    "            \n",
    "            current_dir = os.path.join(base_dir, folder_name, split, label)\n",
    "            if not os.path.exists(current_dir):\n",
    "                print(f\"Directory not found: {current_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # 해당 디렉토리의 모든 wav 파일 처리\n",
    "            for filename in tqdm(os.listdir(current_dir), desc=f'Processing {folder_name}/{split}/{label}'):\n",
    "                if filename.endswith('.wav'):\n",
    "                    file_path = os.path.join(current_dir, filename)\n",
    "                    \n",
    "                    try:\n",
    "                        # 특징 추출\n",
    "                        features = extract_features(file_path)\n",
    "                        \n",
    "                        # 각 특징을 개별적으로 저장\n",
    "                        for feature_type, feature_data in features.items():\n",
    "                            save_path = os.path.join(label_save_dir, feature_type, \n",
    "                                                   filename.replace('.wav', '.npy'))\n",
    "                            np.save(save_path, feature_data)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "\n",
    "print(\"Processing completed!\")\n",
    "\n",
    "# 샘플 데이터 shape 확인\n",
    "def check_saved_features(save_dir):\n",
    "    print(\"\\nChecking saved features shapes...\")\n",
    "    for folder_name in ['for-2seconds', 'for-rerecorded']:\n",
    "        split_dir = os.path.join(save_dir, folder_name, 'training')\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "            \n",
    "        label_dir = os.path.join(split_dir, 'fake')  # 임의의 레이블 선택\n",
    "        if not os.path.exists(label_dir):\n",
    "            continue\n",
    "            \n",
    "        for feature_type in ['melspec', 'melspec_delta', 'melspec_delta_delta', \n",
    "                           'lfcc', 'lfcc_delta', 'lfcc_delta_delta']:\n",
    "            feature_dir = os.path.join(label_dir, feature_type)\n",
    "            if not os.path.exists(feature_dir):\n",
    "                continue\n",
    "                \n",
    "            # 첫 번째 파일 확인\n",
    "            first_file = next((f for f in os.listdir(feature_dir) if f.endswith('.npy')), None)\n",
    "            if first_file:\n",
    "                feature_path = os.path.join(feature_dir, first_file)\n",
    "                feature_data = np.load(feature_path)\n",
    "                print(f\"{feature_type}: {feature_data.shape}\")\n",
    "\n",
    "check_saved_features(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb81540cd42839",
   "metadata": {},
   "source": [
    "# Melspectrogram 등 주파수 추출기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be4777e3d068a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T10:06:34.475263Z",
     "start_time": "2024-11-25T10:02:38.982424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for-2seconds/training/fake: 100%|██████████| 6978/6978 [00:32<00:00, 217.43it/s]\n",
      "Processing for-2seconds/training/real: 100%|██████████| 6978/6978 [00:57<00:00, 121.35it/s]\n",
      "Processing for-2seconds/testing/fake: 100%|██████████| 544/544 [00:04<00:00, 123.01it/s]\n",
      "Processing for-2seconds/testing/real: 100%|██████████| 544/544 [00:04<00:00, 109.53it/s]\n",
      "Processing for-2seconds/validation/fake: 100%|██████████| 1413/1413 [00:12<00:00, 115.95it/s]\n",
      "Processing for-2seconds/validation/real: 100%|██████████| 1413/1413 [00:11<00:00, 120.29it/s]\n",
      "Processing for-rerecorded/training/fake: 100%|██████████| 5104/5104 [00:41<00:00, 121.55it/s]\n",
      "Processing for-rerecorded/training/real: 100%|██████████| 5104/5104 [00:43<00:00, 118.05it/s]\n",
      "Processing for-rerecorded/testing/fake: 100%|██████████| 408/408 [00:03<00:00, 113.60it/s]\n",
      "Processing for-rerecorded/testing/real: 100%|██████████| 408/408 [00:03<00:00, 116.95it/s]\n",
      "Processing for-rerecorded/validation/fake: 100%|██████████| 1143/1143 [00:09<00:00, 125.69it/s]\n",
      "Processing for-rerecorded/validation/real: 100%|██████████| 1101/1101 [00:10<00:00, 104.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_saved_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 181\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# 결과 확인\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mcheck_saved_features\u001b[49m(save_dir)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_saved_features' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 기본 설정\n",
    "TARGET_SR = 16000  # 논문에서 사용한 샘플링 레이트\n",
    "TARGET_LENGTH = 64600  # 4초 * 16000Hz = 64000 (약간의 여유 추가)\n",
    "TARGET_SIZE = (64, 64)  # 목표 특징 크기\n",
    "\n",
    "class RawboostAugment:\n",
    "    def __init__(self, max_db=10, device='cuda'):\n",
    "        self.max_db = max_db\n",
    "        self.device = device\n",
    "    \n",
    "    def __call__(self, waveform):\n",
    "        # 1. Random gain\n",
    "        gain_db = torch.empty(1, device=self.device).uniform_(-self.max_db, self.max_db)\n",
    "        gain_factor = 10 ** (gain_db / 20)\n",
    "        waveform = waveform * gain_factor\n",
    "        \n",
    "        # 2. Add noise\n",
    "        noise = torch.randn_like(waveform, device=self.device) * 0.001\n",
    "        waveform = waveform + noise\n",
    "        \n",
    "        # 3. Clip to [-1, 1]\n",
    "        waveform = torch.clamp(waveform, -1, 1)\n",
    "        \n",
    "        return waveform\n",
    "\n",
    "def fix_length(waveform, target_length):\n",
    "    \"\"\"Fix audio length to target length\"\"\"\n",
    "    curr_length = waveform.size(-1)\n",
    "    \n",
    "    if curr_length > target_length:\n",
    "        # Truncate\n",
    "        waveform = waveform[..., :target_length]\n",
    "    elif curr_length < target_length:\n",
    "        # Repeat and truncate\n",
    "        num_repeats = (target_length + curr_length - 1) // curr_length\n",
    "        waveform = waveform.repeat(1, num_repeats)\n",
    "        waveform = waveform[..., :target_length]\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "# 특징 추출기 설정\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, device='cuda'):\n",
    "        self.device = device\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=TARGET_SR,\n",
    "            n_mels=64,\n",
    "            n_fft=2048,\n",
    "            hop_length=512,\n",
    "            power=2\n",
    "        ).to(device)\n",
    "        \n",
    "        self.lfcc_transform = torchaudio.transforms.LFCC(\n",
    "            sample_rate=TARGET_SR,\n",
    "            n_lfcc=64,\n",
    "            n_filter=128,\n",
    "            speckwargs={\"n_fft\": 2048, \"hop_length\": 512}\n",
    "        ).to(device)\n",
    "        \n",
    "        self.compute_deltas = torchaudio.transforms.ComputeDeltas().to(device)\n",
    "        self.to_db = torchaudio.transforms.AmplitudeToDB().to(device)\n",
    "        self.rawboost = RawboostAugment()\n",
    "    \n",
    "    def extract_features(self, waveform, is_training=False):\n",
    "        # 입력 웨이브폼을 지정된 디바이스로 이동\n",
    "        waveform = waveform.to(self.device)\n",
    "        \n",
    "        # 학습 중일 경우 Rawboost 적용\n",
    "        if is_training:\n",
    "            waveform = self.rawboost(waveform.to(self.device))\n",
    "        \n",
    "        # Mel-spectrogram 특징 추출\n",
    "        mel_spec = self.mel_transform(waveform)\n",
    "        mel_spec_db = self.to_db(mel_spec)\n",
    "        mel_deltas = self.compute_deltas(mel_spec_db)\n",
    "        mel_delta_deltas = self.compute_deltas(mel_deltas)\n",
    "        \n",
    "        # LFCC 특징 추출\n",
    "        lfcc = self.lfcc_transform(waveform)\n",
    "        lfcc_deltas = self.compute_deltas(lfcc)\n",
    "        lfcc_delta_deltas = self.compute_deltas(lfcc_deltas)\n",
    "        \n",
    "        # 특징 크기 조정\n",
    "        features = {\n",
    "            'melspec': self._resize_feature(mel_spec_db),\n",
    "            'melspec_delta': self._resize_feature(mel_deltas),\n",
    "            'melspec_delta_delta': self._resize_feature(mel_delta_deltas),\n",
    "            'lfcc': self._resize_feature(lfcc),\n",
    "            'lfcc_delta': self._resize_feature(lfcc_deltas),\n",
    "            'lfcc_delta_delta': self._resize_feature(lfcc_delta_deltas)\n",
    "        }\n",
    "        \n",
    "        # CPU로 이동하고 numpy로 변환하기 전에 모든 특징을 동일한 디바이스에 있도록 함\n",
    "        return {k: v.detach().cpu().numpy() for k, v in features.items()}\n",
    "\n",
    "    \n",
    "    def _resize_feature(self, feature):\n",
    "        # Interpolate to target size\n",
    "        feature = feature.unsqueeze(0)  # Add batch dimension\n",
    "        feature = F.interpolate(feature, size=TARGET_SIZE, mode='bilinear', align_corners=False)\n",
    "        feature = feature.squeeze(0)  # Remove batch dimension\n",
    "        return feature\n",
    "\n",
    "def process_dataset(base_dir, save_dir, device='cuda'):\n",
    "    feature_extractor = FeatureExtractor(device)\n",
    "    \n",
    "    for folder_name in ['for-2seconds', 'for-rerecorded']:\n",
    "        dataset_save_dir = os.path.join(save_dir, folder_name)\n",
    "        os.makedirs(dataset_save_dir, exist_ok=True)\n",
    "        \n",
    "        for split in ['training', 'testing', 'validation']:\n",
    "            split_save_dir = os.path.join(dataset_save_dir, split)\n",
    "            os.makedirs(split_save_dir, exist_ok=True)\n",
    "            \n",
    "            for label in ['fake', 'real']:\n",
    "                label_save_dir = os.path.join(split_save_dir, label)\n",
    "                os.makedirs(label_save_dir, exist_ok=True)\n",
    "                \n",
    "                # 각 특징 타입에 대한 디렉토리 생성\n",
    "                for feature_type in ['melspec', 'melspec_delta', 'melspec_delta_delta', \n",
    "                                   'lfcc', 'lfcc_delta', 'lfcc_delta_delta']:\n",
    "                    os.makedirs(os.path.join(label_save_dir, feature_type), exist_ok=True)\n",
    "                \n",
    "                current_dir = os.path.join(base_dir, folder_name, split, label)\n",
    "                if not os.path.exists(current_dir):\n",
    "                    print(f\"Directory not found: {current_dir}\")\n",
    "                    continue\n",
    "                \n",
    "                # 파일 처리\n",
    "                for filename in tqdm(os.listdir(current_dir), \n",
    "                                   desc=f'Processing {folder_name}/{split}/{label}'):\n",
    "                    if filename.endswith('.wav'):\n",
    "                        file_path = os.path.join(current_dir, filename)\n",
    "                        \n",
    "                        try:\n",
    "                            # 오디오 로드 및 전처리\n",
    "                            waveform, sr = torchaudio.load(file_path)\n",
    "                            \n",
    "                            # 리샘플링\n",
    "                            if sr != TARGET_SR:\n",
    "                                waveform = torchaudio.transforms.Resample(sr, TARGET_SR)(waveform)\n",
    "                            \n",
    "                            # 길이 조정\n",
    "                            waveform = fix_length(waveform, TARGET_LENGTH)\n",
    "                            \n",
    "                            # 특징 추출\n",
    "                            features = feature_extractor.extract_features(\n",
    "                                waveform, \n",
    "                                is_training=(split == 'training')\n",
    "                            )\n",
    "                            \n",
    "                            # 특징 저장\n",
    "                            for feature_type, feature_data in features.items():\n",
    "                                save_path = os.path.join(label_save_dir, feature_type, \n",
    "                                                       filename.replace('.wav', '.npy'))\n",
    "                                np.save(save_path, feature_data)\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = r\"C:\\Users\\tjdwn\\Downloads\\archive\"\n",
    "    save_dir = \"audio_features\"\n",
    "    \n",
    "    # GPU 사용 가능 여부 확인\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 데이터셋 처리\n",
    "    process_dataset(base_dir, save_dir, device)\n",
    "    print(\"Processing completed!\")\n",
    "    \n",
    "    # 결과 확인\n",
    "    check_saved_features(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4144c387b6da9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda9fd84e6b74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
